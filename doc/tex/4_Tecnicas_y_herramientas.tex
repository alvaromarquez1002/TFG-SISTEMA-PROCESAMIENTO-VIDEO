
\chapter{Técnicas y herramientas}
\label{chap:tecnicas_herramientas}

En este capítulo describo las principales tecnologías, lenguajes de programación y herramientas que han constituido la base para el desarrollo de mi Trabajo de Fin de Grado. Mi elección de cada una de ellas responde a las necesidades específicas de construir una infraestructura de procesamiento de vídeo que fuera robusta, escalable y reproducible.

\section{Herramientas de Desarrollo y Gestión}
\label{sec:herramientas_desarrollo}

\subsection{Python}
El lenguaje principal que he utilizado para desarrollar la lógica del proyecto ha sido \textbf{Python} \cite{python_software_foundation}. Lo elegí por su sintaxis clara, que facilita un desarrollo rápido, y por su enorme ecosistema de librerías, especialmente en el ámbito del procesamiento de datos, lo que lo hace ideal para integrarse con las tecnologías de Big Data que necesitaba para mi TFG.

\subsection{Jira y Metodología Ágil}
Para gestionar el proyecto, decidí emplear un enfoque ágil basado en \textbf{Scrum} \cite{trigas2012metodologia}, utilizando \textbf{Jira} \cite{atlassian_jira} como herramienta de soporte. Esta metodología me ha permitido organizar el trabajo en Épicas y Sprints, mantener un backlog de tareas actualizado y visualizar el progreso en un tablero Kanban. Este enfoque ha sido fundamental para poder adaptarme a los imprevistos y a los desafíos técnicos que surgieron, manteniendo siempre un seguimiento claro del trabajo realizado.

\subsection{Git y GitHub}
Para el control de versiones he utilizado \textbf{Git}, y he alojado el proyecto en un repositorio privado en \textbf{GitHub}. Esta práctica ha sido esencial para mantener un historial de cambios detallado, trabajar de forma segura y asegurar la integridad de todo el código y la documentación.

\section{Infraestructura y Pipeline de Datos}
\label{sec:herramientas_infraestructura}
El núcleo del proyecto reside en la infraestructura que he diseñado para capturar, transportar y procesar los datos de vídeo.

\subsection{Sistema Operativo Base: Debian 12}
Tras encontrar numerosos problemas de compatibilidad y permisos en Windows con WSL2, tomé la decisión de migrar todo el entorno de desarrollo a un sistema operativo Linux nativo. La elección fue \textbf{Debian 12}, principalmente por su reconocida estabilidad y por ser un estándar en entornos de servidor, lo que me garantizaba un comportamiento más predecible de las herramientas de red y de Docker.

\subsection{Contenerización con Docker y Docker Compose}
Desde el principio tuve claro que la contenerización era necesaria para este proyecto. He utilizado \textbf{Docker} \cite{docker_docs} para empaquetar cada servicio (Kafka, Zookeeper, mi aplicación Python) en contenedores aislados. Esto garantiza que el entorno sea reproducible y evita los clásicos problemas de dependencias entre distintas máquinas.

Para orquestar todos estos contenedores, he usado \textbf{Docker Compose}. Mediante un único archivo \texttt{docker-compose.yml}, he podido definir toda la arquitectura de la aplicación, incluyendo la red que los conecta y las dependencias de arranque, lo que ha simplificado enormemente el despliegue y las pruebas del sistema completo.

\subsection{Captura de Vídeo: Jitsi y Jibri}
Como fuente de los datos de vídeo he utilizado la plataforma de código abierto \textbf{Jitsi} \cite{JitsiJibriDocs}. En concreto, el componente clave para mi proyecto es \textbf{Jibri} (Jitsi Broadcasting Infrastructure). Su función es unirse a una conferencia y grabarla en un archivo de vídeo \textbf{MP4}, que se convierte en el dato de entrada para mi pipeline de procesamiento. Elegí Jitsi por ser una solución completa y gratuita que me proporcionaba la funcionalidad de captura que necesitaba.

\subsection{Pipeline de Datos: Apache Kafka y Apache Spark}
La arquitectura de procesamiento se basa en un pipeline de datos en streaming.
\begin{itemize}
    \item \textbf{Apache Kafka} \cite{KafkaWebDoc}: En mi arquitectura, Kafka actúa como un sistema intermediario que desacopla el sistema de captura del de procesamiento. Su función es recibir los datos de Jibri de forma fiable y almacenarlos en \textit{topics} hasta que Spark esté listo para consumirlos. Lo escogí por su alta capacidad para manejar grandes volúmenes de datos y su tolerancia a fallos.
    \item \textbf{Apache Spark} \cite{SparkWebDoc}: Para el análisis del vídeo, la herramienta seleccionada es Spark. Su principal ventaja para mi TFG es su potente motor de procesamiento distribuido y su flexibilidad para trabajar tanto con datos en streaming como con archivos estáticos (batch). He utilizado su API de Python, \textbf{PySpark}, para desarrollar los scripts de procesamiento.
\end{itemize}

\section{Herramientas de Documentación}
\subsection{\LaTeX{} y Overleaf}
Para la redacción de esta memoria, he utilizado el sistema de composición de textos \textbf{\LaTeX{}} \cite{wiki:latex} por la alta calidad profesional de sus resultados. Todo el trabajo de redacción lo he realizado sobre \textbf{Overleaf}, un editor en línea que facilita enormemente la escritura y compilación de documentos \LaTeX{} sin necesidad de instalaciones locales.