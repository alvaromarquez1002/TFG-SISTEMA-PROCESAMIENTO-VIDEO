\capitulo{4}{Técnicas y herramientas}

\subsection{Metodología de Desarrollo}

Para organizar y gestionar el trabajo de este TFG de una manera flexible y adaptativa, se ha decidido emplear un enfoque ágil.

Las ideas principales de esta forma de trabajo aplicada al TFG son:

\begin{itemize}
    \item \textbf{Organización en Sprints:} El trabajo total se divide en periodos de tiempo, los Sprints. En cada Sprint, el objetivo es completar un conjunto concreto de tareas previamente seleccionadas.
    
    \item \textbf{Uso de Jira para la Gestión:} Se utiliza la herramienta de software \textbf{Jira} como soporte principal para la gestión del proyecto. En Jira creo:
        \begin{itemize}
            \item Una lista general de tareas pendientes (Backlog).
            \item La planificación de qué tareas se abordarán en cada Sprint.
            \item Un tablero visual para seguir el estado de las tareas del Sprint actual (si están Por Hacer, En Curso o ya Hechas).
            \item Se usan también Épicas para agrupar fases grandes del proyecto (como la investigación inicial, el desarrollo de componentes, la escritura de la documentación, etc.).
        \end{itemize}
    
    \item \textbf{Seguimiento y Adaptación:} Se mantienen reuniones periódicas (normalmente semanales) con los tutores para revisar el trabajo realizado en el Sprint, comentar los avances, resolver dudas o problemas...
\end{itemize}

Este enfoque ágil resulta beneficioso, ya que permite adaptarse mejor a los resultados de la investigación o a los desafíos técnicos que puedan surgir, a la vez que facilita un seguimiento continuo del progreso hacia los objetivos finales.

\subsubsection{Apache Kafka}

Apache Kafka \cite{KafkaWebDoc} es una plataforma distribuida de código abierto, ampliamente reconocida en la industria, diseñada específicamente para la gestión y procesamiento de flujos de eventos en tiempo real. Funciona como un sistema de mensajería publicar-suscribir de alto rendimiento, que garantiza durabilidad y tolerancia a fallos.

% Rol en este TFG
En el marco de este proyecto, Apache Kafka se perfila como una pieza central de la arquitectura. Su rol principal será actuar como el sistema intermediario encargado de recibir de forma eficiente los flujos de datos generados por la fuente de vídeo (Jitsi/Jibri) y almacenarlos temporalmente de manera fiable para que sean consumidos posteriormente por el motor de procesamiento (Apache Spark). Esto aportando flexibilidad y robustez al conjunto.

% Justificación / Por qué Kafka
La elección de Kafka se fundamenta en:
\begin{itemize}
    \item \textbf{Manejo de Alto Volumen y Baja Latencia:} Kafka está optimizado para ingestar y servir grandes cantidades de datos (como los que puede generar el vídeo) con un retardo mínimo.
    \item \textbf{Escalabilidad Nativa:} El sistema permite escalar la capacidad de Kafka para adaptarse a la carga de trabajo.
    \item \textbf{Fiabilidad:} Su naturaleza distribuida y la duplicación de datos proporcionan tolerancia a fallos.
\end{itemize}

% Zookeeper / KRaft
Es relevante mencionar que Kafka requiere de Apache Zookeeper para tareas de coordinación y gestión de metadatos. Aunque esta dependencia está siendo eliminada en las versiones más recientes mediante el protocolo KRaft (que simplifica la infraestructura), es un factor a tener en cuenta según la versión que finalmente se despliegue en el proyecto.

% Consideraciones y Alternativas
Una consideración técnica es que Kafka no está optimizado para manejar archivos de vídeo extremadamente grandes como mensajes únicos; se deben considerar estrategias como el envío de metadatos. Kafka es una opción preferente para este proyecto.

\subsubsection{Apache Spark}

Para realizar el procesamiento y análisis de los datos de vídeo (ya sean los flujos recibidos a través de Kafka o los archivos MP4 grabados), la herramienta principal que he seleccionado es \textbf{Apache Spark} \cite{SparkWebDoc}. Se trata de un motor de análisis unificado y muy potente, diseñado para procesar grandes volúmenes de datos de forma distribuida y eficiente.

La razón principal para elegir Spark en este TFG es su capacidad para manejar tanto el procesamiento por lotes (batch) como el procesamiento en tiempo real (streaming) utilizando una misma plataforma y APIs consistentes, especialmente a través de su interfaz para Python (\textit{PySpark}). Esto me da flexibilidad para implementar tanto el flujo offline como un posible flujo en tiempo real.

Además, considero que Spark es adecuado por:
\begin{itemize}
    \item Su buena integración con el ecosistema Big Data, incluyendo una conexión nativa y robusta con Apache Kafka, así como con sistemas de almacenamiento como HDFS o almacenes compatibles con S3 (útil para leer los MP4s grabados).
    \item Sus librerías incorporadas, como \textit{Spark SQL} (que podría usar para analizar metadatos o características extraídas de los vídeos) y MLlib (su librería de Machine Learning).
    \item La disponibilidad de una API en Python (PySpark), que facilita su uso dado que el resto del desarrollo probablemente se realizará en este lenguaje.
\end{itemize}

Soy consciente de que el procesamiento de vídeo puede ser intensivo en recursos, especialmente en memoria, por lo que la configuración y optimización del clúster será un aspecto importante a tener en cuenta durante la implementación.

\subsubsection{Jitsi / Jibri}


Para la captura del vídeo de las sesiones de rehabilitación, que es la fuente de datos principal de este proyecto, he decidido basarme en la plataforma de videoconferencia de código abierto \textbf{Jitsi} \cite{JitsiJibriDocs}. Jitsi es un conjunto de herramientas que permiten crear sistemas de videoconferencia seguros y escalables. Sus componentes principales son Jitsi Meet (la aplicación web/móvil para los usuarios) y Jitsi Videobridge (el servidor que gestiona los flujos de vídeo).

Dentro del ecosistema Jitsi, el componente clave para mi TFG es \textbf{Jibri} (Jitsi Broadcasting Infrastructure). Jibri es una herramienta diseñada específicamente para grabar o transmitir una conferencia completa de Jitsi Meet.

El rol de Jibri en mi proyecto es fundamental: será el encargado de generar los datos de vídeo brutos que posteriormente procesará Spark. Según el enfoque que siga (offline o tiempo real), utilizaré Jibri para:
\begin{itemize}
    \item \textbf{Grabar las sesiones} de ejercicios en archivos de vídeo estándar (formato MP4). Esta es la opción inicial más recomendada.
    \item O bien transmitir la sesión en tiempo real usando el protocolo RTMP, lo que requeriría una integración más compleja con Kafka o un intermediario.
\end{itemize}

La elección de Jitsi/Jibri se basa en que es una solución \textbf{completa, de código abierto y gratuita}, que me proporciona directamente la funcionalidad de captura y grabación/streaming de vídeo necesaria como punto de partida para mi pipeline de procesamiento.

No obstante, soy consciente de algunas consideraciones importantes al usar Jibri: requiere una máquina (o máquina virtual) dedicada con recursos suficientes (CPU, RAM), y una única instancia de Jibri solo puede gestionar una grabación o transmisión a la vez, lo que implica pensar en la escalabilidad si se necesitaran muchas sesiones concurrentes.